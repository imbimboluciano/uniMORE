{"cells":[{"cell_type":"markdown","metadata":{"id":"fkeIr_HQobkZ"},"source":["# Pipelines"]},{"cell_type":"markdown","metadata":{"id":"Kn_BdZ38obkc"},"source":["* Pipelines sequentially apply **a list of transforms** and a **final estimator**.\n","\n","    * Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods.\n","    * The final estimator only needs to implement fit.\n","\n","* The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"HaY7hcyQobke"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"WNX6zRPIobks"},"outputs":[],"source":["from sklearn import datasets\n","iris = datasets.load_iris()\n","\n","X = iris.data\n","y = iris.target\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n","                                                      random_state=0)"]},{"cell_type":"markdown","metadata":{"id":"-hcH6_S9obk3"},"source":["## Simple Pipeline"]},{"cell_type":"markdown","metadata":{"id":"9PJZzOKLobk5"},"source":["The simple pipeline is composed of the folloing steps:\n","- Transformation\n","    - Scaling values between 0 and 1\n","    - PCA (we keep 2 components)\n","- Estimator\n","    - Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"gfv2Ygq0obk7"},"source":["### Transformation\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"pgmMtRPRVqt7"},"outputs":[{"data":{"text/plain":["['sepal length (cm)',\n"," 'sepal width (cm)',\n"," 'petal length (cm)',\n"," 'petal width (cm)']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["iris.feature_names"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"oWw0JuYMobk9"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import Normalizer\n","\n","preprocessing_transformer = Pipeline(steps=[('normalize', Normalizer()),\n","                                             ('scale_01', MinMaxScaler(feature_range=(0, 1))),\n","                                             ('PCA', PCA(n_components=2))])\n","# preprocessing_transformer = Pipeline(steps=[('scale_01', MinMaxScaler(feature_range=(0, 1))),\n","#                                             ('PioggiaPCA', PCA(n_components=2))])"]},{"cell_type":"markdown","metadata":{"id":"ee5H2EcYoblG"},"source":["### Estimator"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"9PCw3m5FoblI"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","model = LogisticRegression(solver='lbfgs', multi_class='auto')"]},{"cell_type":"markdown","metadata":{"id":"xf_pJVC7oblO"},"source":["### Creating and evaluating the Pipeline"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-QCkecdPoblP"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Pipeline]  (step 1 of 2) Processing preprocessing_transformer, total=   0.0s\n","[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n","Accuracy Score: 0.9666666666666667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]}],"source":["from sklearn.metrics import accuracy_score\n","\n","# Bundle preprocessing and modeling code in a pipeline\n","my_pipeline = Pipeline(steps=[('preprocessing_transformer', preprocessing_transformer),\n","                               ('model', model)\n","                              ], verbose = True)\n","\n","# my_pipeline = Pipeline(steps=[('scale_01', MinMaxScaler(feature_range=(0, 1))),\n","#                              ('PioggiaPCA', PCA(n_components=2)),\n","#                              ('model', model)\n","#                             ], verbose = True)\n","\n","# Preprocessing of training data, fit model\n","my_pipeline.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = my_pipeline.predict(X_valid)\n","\n","# Evaluate the model\n","score = accuracy_score(y_valid, preds)\n","print('Accuracy Score:', score)"]},{"cell_type":"markdown","metadata":{"id":"HQNHwkbaoblW"},"source":["### Analyzing the transformation"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"rpowm18ByEa4"},"outputs":[{"data":{"text/plain":["array([[6.4, 3.1, 5.5, 1.8],\n","       [5.4, 3. , 4.5, 1.5],\n","       [5.2, 3.5, 1.5, 0.2],\n","       [6.1, 3. , 4.9, 1.8],\n","       [6.4, 2.8, 5.6, 2.2],\n","       [5.2, 2.7, 3.9, 1.4],\n","       [5.7, 3.8, 1.7, 0.3],\n","       [6. , 2.7, 5.1, 1.6],\n","       [5.9, 3. , 4.2, 1.5],\n","       [5.8, 2.6, 4. , 1.2],\n","       [6.8, 3. , 5.5, 2.1],\n","       [4.7, 3.2, 1.3, 0.2],\n","       [6.9, 3.1, 5.1, 2.3],\n","       [5. , 3.5, 1.6, 0.6],\n","       [5.4, 3.7, 1.5, 0.2],\n","       [5. , 2. , 3.5, 1. ],\n","       [6.5, 3. , 5.5, 1.8],\n","       [6.7, 3.3, 5.7, 2.5],\n","       [6. , 2.2, 5. , 1.5],\n","       [6.7, 2.5, 5.8, 1.8],\n","       [5.6, 2.5, 3.9, 1.1],\n","       [7.7, 3. , 6.1, 2.3],\n","       [6.3, 3.3, 4.7, 1.6],\n","       [5.5, 2.4, 3.8, 1.1],\n","       [6.3, 2.7, 4.9, 1.8],\n","       [6.3, 2.8, 5.1, 1.5],\n","       [4.9, 2.5, 4.5, 1.7],\n","       [6.3, 2.5, 5. , 1.9],\n","       [7. , 3.2, 4.7, 1.4],\n","       [6.5, 3. , 5.2, 2. ],\n","       [6. , 3.4, 4.5, 1.6],\n","       [4.8, 3.1, 1.6, 0.2],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [5.6, 2.7, 4.2, 1.3],\n","       [5.6, 2.9, 3.6, 1.3],\n","       [5.5, 2.5, 4. , 1.3],\n","       [6.1, 3. , 4.6, 1.4],\n","       [7.2, 3.2, 6. , 1.8],\n","       [5.3, 3.7, 1.5, 0.2],\n","       [4.3, 3. , 1.1, 0.1],\n","       [6.4, 2.7, 5.3, 1.9],\n","       [5.7, 3. , 4.2, 1.2],\n","       [5.4, 3.4, 1.7, 0.2],\n","       [5.7, 4.4, 1.5, 0.4],\n","       [6.9, 3.1, 4.9, 1.5],\n","       [4.6, 3.1, 1.5, 0.2],\n","       [5.9, 3. , 5.1, 1.8],\n","       [5.1, 2.5, 3. , 1.1],\n","       [4.6, 3.4, 1.4, 0.3],\n","       [6.2, 2.2, 4.5, 1.5],\n","       [7.2, 3.6, 6.1, 2.5],\n","       [5.7, 2.9, 4.2, 1.3],\n","       [4.8, 3. , 1.4, 0.1],\n","       [7.1, 3. , 5.9, 2.1],\n","       [6.9, 3.2, 5.7, 2.3],\n","       [6.5, 3. , 5.8, 2.2],\n","       [6.4, 2.8, 5.6, 2.1],\n","       [5.1, 3.8, 1.6, 0.2],\n","       [4.8, 3.4, 1.6, 0.2],\n","       [6.5, 3.2, 5.1, 2. ],\n","       [6.7, 3.3, 5.7, 2.1],\n","       [4.5, 2.3, 1.3, 0.3],\n","       [6.2, 3.4, 5.4, 2.3],\n","       [4.9, 3. , 1.4, 0.2],\n","       [5.7, 2.5, 5. , 2. ],\n","       [6.9, 3.1, 5.4, 2.1],\n","       [4.4, 3.2, 1.3, 0.2],\n","       [5. , 3.6, 1.4, 0.2],\n","       [7.2, 3. , 5.8, 1.6],\n","       [5.1, 3.5, 1.4, 0.3],\n","       [4.4, 3. , 1.3, 0.2],\n","       [5.4, 3.9, 1.7, 0.4],\n","       [5.5, 2.3, 4. , 1.3],\n","       [6.8, 3.2, 5.9, 2.3],\n","       [7.6, 3. , 6.6, 2.1],\n","       [5.1, 3.5, 1.4, 0.2],\n","       [4.9, 3.1, 1.5, 0.2],\n","       [5.2, 3.4, 1.4, 0.2],\n","       [5.7, 2.8, 4.5, 1.3],\n","       [6.6, 3. , 4.4, 1.4],\n","       [5. , 3.2, 1.2, 0.2],\n","       [5.1, 3.3, 1.7, 0.5],\n","       [6.4, 2.9, 4.3, 1.3],\n","       [5.4, 3.4, 1.5, 0.4],\n","       [7.7, 2.6, 6.9, 2.3],\n","       [4.9, 2.4, 3.3, 1. ],\n","       [7.9, 3.8, 6.4, 2. ],\n","       [6.7, 3.1, 4.4, 1.4],\n","       [5.2, 4.1, 1.5, 0.1],\n","       [6. , 3. , 4.8, 1.8],\n","       [5.8, 4. , 1.2, 0.2],\n","       [7.7, 2.8, 6.7, 2. ],\n","       [5.1, 3.8, 1.5, 0.3],\n","       [4.7, 3.2, 1.6, 0.2],\n","       [7.4, 2.8, 6.1, 1.9],\n","       [5. , 3.3, 1.4, 0.2],\n","       [6.3, 3.4, 5.6, 2.4],\n","       [5.7, 2.8, 4.1, 1.3],\n","       [5.8, 2.7, 3.9, 1.2],\n","       [5.7, 2.6, 3.5, 1. ],\n","       [6.4, 3.2, 5.3, 2.3],\n","       [6.7, 3. , 5.2, 2.3],\n","       [6.3, 2.5, 4.9, 1.5],\n","       [6.7, 3. , 5. , 1.7],\n","       [5. , 3. , 1.6, 0.2],\n","       [5.5, 2.4, 3.7, 1. ],\n","       [6.7, 3.1, 5.6, 2.4],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [5.1, 3.4, 1.5, 0.2],\n","       [6.6, 2.9, 4.6, 1.3],\n","       [5.6, 3. , 4.1, 1.3],\n","       [5.9, 3.2, 4.8, 1.8],\n","       [6.3, 2.3, 4.4, 1.3],\n","       [5.5, 3.5, 1.3, 0.2],\n","       [5.1, 3.7, 1.5, 0.4],\n","       [4.9, 3.1, 1.5, 0.1],\n","       [6.3, 2.9, 5.6, 1.8],\n","       [5.8, 2.7, 4.1, 1. ],\n","       [7.7, 3.8, 6.7, 2.2],\n","       [4.6, 3.2, 1.4, 0.2]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["X_train"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"kjyEx669oblY"},"outputs":[],"source":["transformed_Dataset = preprocessing_transformer.fit_transform(X_train)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"xqdpcrCiyewK"},"outputs":[],"source":["#preprocessing_transformer.transform(X_valid)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"b5NysW3aWxda"},"outputs":[{"data":{"text/plain":["array([[ 0.48187891, -0.08794552],\n","       [ 0.39447387, -0.19185301],\n","       [-0.82742985, -0.00776855],\n","       [ 0.43554794, -0.08147243],\n","       [ 0.63857614, -0.08186638],\n","       [ 0.30759918, -0.07433297],\n","       [-0.78595435, -0.00622101],\n","       [ 0.47310646, -0.00917393],\n","       [ 0.2417868 , -0.01815521],\n","       [ 0.17135009,  0.15847256],\n","       [ 0.5044493 , -0.01085657],\n","       [-0.83748787, -0.02827408],\n","       [ 0.4603074 , -0.00978699],\n","       [-0.63653012, -0.14596354],\n","       [-0.84699402, -0.03374869],\n","       [ 0.20913949,  0.2511393 ],\n","       [ 0.47705843, -0.03663131],\n","       [ 0.6178794 , -0.1890083 ],\n","       [ 0.49168655,  0.16197931],\n","       [ 0.55533544,  0.10811145],\n","       [ 0.16253613,  0.16840577],\n","       [ 0.50934561,  0.10026196],\n","       [ 0.27280092, -0.06517446],\n","       [ 0.16924271,  0.1877243 ],\n","       [ 0.43835032,  0.05529122],\n","       [ 0.38120198,  0.05533612],\n","       [ 0.63234123, -0.22810484],\n","       [ 0.51014492,  0.08361224],\n","       [ 0.12789826,  0.15997216],\n","       [ 0.47647868, -0.03965675],\n","       [ 0.26985636, -0.15813733],\n","       [-0.75243356,  0.04652681],\n","       [ 0.59459157, -0.11414648],\n","       [ 0.26942603,  0.03110391],\n","       [ 0.10643667,  0.02395091],\n","       [ 0.26881715,  0.09209808],\n","       [ 0.26287527,  0.01344578],\n","       [ 0.42988475,  0.02776959],\n","       [-0.84087703, -0.06475662],\n","       [-0.90415646, -0.04975116],\n","       [ 0.5213199 ,  0.02255662],\n","       [ 0.18337593, -0.02192506],\n","       [-0.78311825,  0.09176672],\n","       [-0.81785046, -0.25833333],\n","       [ 0.21657377,  0.13255717],\n","       [-0.76621705, -0.01884916],\n","       [ 0.50872933, -0.15483569],\n","       [ 0.02136128,  0.12556424],\n","       [-0.76867477, -0.18305593],\n","       [ 0.35604957,  0.2716777 ],\n","       [ 0.56578474, -0.17303236],\n","       [ 0.22651353, -0.00637574],\n","       [-0.84543126,  0.12038241],\n","       [ 0.52216693,  0.02069955],\n","       [ 0.54764493, -0.08568376],\n","       [ 0.62918572, -0.12624255],\n","       [ 0.61289015, -0.06583489],\n","       [-0.8044943 , -0.17538899],\n","       [-0.76701236, -0.09694589],\n","       [ 0.43517231, -0.08466857],\n","       [ 0.51945362, -0.12845012],\n","       [-0.72176951,  0.3544962 ],\n","       [ 0.59302911, -0.28901516],\n","       [-0.81246781,  0.13433953],\n","       [ 0.65169041, -0.09235101],\n","       [ 0.4601912 , -0.00413277],\n","       [-0.81478862, -0.13894717],\n","       [-0.84428291, -0.11670904],\n","       [ 0.37040809,  0.12306752],\n","       [-0.81074183, -0.05486422],\n","       [-0.80654106, -0.0348423 ],\n","       [-0.73521837, -0.15376843],\n","       [ 0.29671532,  0.15979792],\n","       [ 0.59562253, -0.12641037],\n","       [ 0.55378275,  0.06227437],\n","       [-0.84755649, -0.03787133],\n","       [-0.78905376,  0.08276381],\n","       [-0.84988692,  0.03934164],\n","       [ 0.30458085, -0.00558715],\n","       [ 0.14585269,  0.15537461],\n","       [-0.88404191,  0.07324259],\n","       [-0.64532514, -0.00716451],\n","       [ 0.13720223,  0.16429023],\n","       [-0.7637771 ,  0.06374822],\n","       [ 0.66829554,  0.11291194],\n","       [ 0.11476134,  0.09084389],\n","       [ 0.38012382, -0.02461453],\n","       [ 0.12075205,  0.14886717],\n","       [-0.87828274, -0.25390658],\n","       [ 0.43398827, -0.09894831],\n","       [-0.94666233, -0.03931871],\n","       [ 0.55310519,  0.12971544],\n","       [-0.7948807 , -0.19022766],\n","       [-0.74957523, -0.03623471],\n","       [ 0.48321034,  0.14154547],\n","       [-0.83346558,  0.02242846],\n","       [ 0.63394274, -0.29342916],\n","       [ 0.21679492,  0.03672528],\n","       [ 0.13584359,  0.13589867],\n","       [ 0.00414927,  0.22293107],\n","       [ 0.5653115 , -0.17521675],\n","       [ 0.52140671, -0.03953065],\n","       [ 0.37981587,  0.16197222],\n","       [ 0.32879742,  0.07453359],\n","       [-0.76153398,  0.15836202],\n","       [ 0.11129187,  0.21846251],\n","       [ 0.60073584, -0.11551626],\n","       [ 0.59459157, -0.11414648],\n","       [-0.81689704,  0.00591756],\n","       [ 0.16947171,  0.18101372],\n","       [ 0.20894645, -0.05795152],\n","       [ 0.42688391, -0.18516216],\n","       [ 0.24658371,  0.31174036],\n","       [-0.89522485,  0.08539357],\n","       [-0.75528782, -0.16314833],\n","       [-0.82759164,  0.10032488],\n","       [ 0.54042165, -0.07002172],\n","       [ 0.11898577,  0.14887481],\n","       [ 0.49442751, -0.11413974],\n","       [-0.80082432, -0.06602023]])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["transformed_Dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"8L5Xs6hgoblc"},"outputs":[{"data":{"text/plain":["numpy.ndarray"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["type(transformed_Dataset)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"FJLKK9PAoblg"},"outputs":[],"source":["tra_df = pd.DataFrame(transformed_Dataset)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"lKHsu-qkoblk"},"outputs":[{"data":{"text/plain":["(120, 2)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tra_df.shape"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"16mGC01Woblo"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.481879</td>\n","      <td>-0.087946</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.394474</td>\n","      <td>-0.191853</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.827430</td>\n","      <td>-0.007769</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.435548</td>\n","      <td>-0.081472</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.638576</td>\n","      <td>-0.081866</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1\n","0  0.481879 -0.087946\n","1  0.394474 -0.191853\n","2 -0.827430 -0.007769\n","3  0.435548 -0.081472\n","4  0.638576 -0.081866"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["tra_df.head()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"TO3kjC_Aobls"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.14611345 0.27292178 0.92949961 0.74911544]\n"," [0.1214028  0.40173613 0.88194002 0.73371565]\n"," [0.71420707 0.83303704 0.13937648 0.06719597]\n"," [0.2177421  0.30550362 0.86886994 0.80557741]]\n"]},{"data":{"text/plain":["array([[ 0.48187891, -0.08794552],\n","       [ 0.39447387, -0.19185301],\n","       [-0.82742985, -0.00776855],\n","       [ 0.43554794, -0.08147243],\n","       [ 0.63857614, -0.08186638],\n","       [ 0.30759918, -0.07433297],\n","       [-0.78595435, -0.00622101],\n","       [ 0.47310646, -0.00917393],\n","       [ 0.2417868 , -0.01815521],\n","       [ 0.17135009,  0.15847256],\n","       [ 0.5044493 , -0.01085657],\n","       [-0.83748787, -0.02827408],\n","       [ 0.4603074 , -0.00978699],\n","       [-0.63653012, -0.14596354],\n","       [-0.84699402, -0.03374869],\n","       [ 0.20913949,  0.2511393 ],\n","       [ 0.47705843, -0.03663131],\n","       [ 0.6178794 , -0.1890083 ],\n","       [ 0.49168655,  0.16197931],\n","       [ 0.55533544,  0.10811145],\n","       [ 0.16253613,  0.16840577],\n","       [ 0.50934561,  0.10026196],\n","       [ 0.27280092, -0.06517446],\n","       [ 0.16924271,  0.1877243 ],\n","       [ 0.43835032,  0.05529122],\n","       [ 0.38120198,  0.05533612],\n","       [ 0.63234123, -0.22810484],\n","       [ 0.51014492,  0.08361224],\n","       [ 0.12789826,  0.15997216],\n","       [ 0.47647868, -0.03965675],\n","       [ 0.26985636, -0.15813733],\n","       [-0.75243356,  0.04652681],\n","       [ 0.59459157, -0.11414648],\n","       [ 0.26942603,  0.03110391],\n","       [ 0.10643667,  0.02395091],\n","       [ 0.26881715,  0.09209808],\n","       [ 0.26287527,  0.01344578],\n","       [ 0.42988475,  0.02776959],\n","       [-0.84087703, -0.06475662],\n","       [-0.90415646, -0.04975116],\n","       [ 0.5213199 ,  0.02255662],\n","       [ 0.18337593, -0.02192506],\n","       [-0.78311825,  0.09176672],\n","       [-0.81785046, -0.25833333],\n","       [ 0.21657377,  0.13255717],\n","       [-0.76621705, -0.01884916],\n","       [ 0.50872933, -0.15483569],\n","       [ 0.02136128,  0.12556424],\n","       [-0.76867477, -0.18305593],\n","       [ 0.35604957,  0.2716777 ],\n","       [ 0.56578474, -0.17303236],\n","       [ 0.22651353, -0.00637574],\n","       [-0.84543126,  0.12038241],\n","       [ 0.52216693,  0.02069955],\n","       [ 0.54764493, -0.08568376],\n","       [ 0.62918572, -0.12624255],\n","       [ 0.61289015, -0.06583489],\n","       [-0.8044943 , -0.17538899],\n","       [-0.76701236, -0.09694589],\n","       [ 0.43517231, -0.08466857],\n","       [ 0.51945362, -0.12845012],\n","       [-0.72176951,  0.3544962 ],\n","       [ 0.59302911, -0.28901516],\n","       [-0.81246781,  0.13433953],\n","       [ 0.65169041, -0.09235101],\n","       [ 0.4601912 , -0.00413277],\n","       [-0.81478862, -0.13894717],\n","       [-0.84428291, -0.11670904],\n","       [ 0.37040809,  0.12306752],\n","       [-0.81074183, -0.05486422],\n","       [-0.80654106, -0.0348423 ],\n","       [-0.73521837, -0.15376843],\n","       [ 0.29671532,  0.15979792],\n","       [ 0.59562253, -0.12641037],\n","       [ 0.55378275,  0.06227437],\n","       [-0.84755649, -0.03787133],\n","       [-0.78905376,  0.08276381],\n","       [-0.84988692,  0.03934164],\n","       [ 0.30458085, -0.00558715],\n","       [ 0.14585269,  0.15537461],\n","       [-0.88404191,  0.07324259],\n","       [-0.64532514, -0.00716451],\n","       [ 0.13720223,  0.16429023],\n","       [-0.7637771 ,  0.06374822],\n","       [ 0.66829554,  0.11291194],\n","       [ 0.11476134,  0.09084389],\n","       [ 0.38012382, -0.02461453],\n","       [ 0.12075205,  0.14886717],\n","       [-0.87828274, -0.25390658],\n","       [ 0.43398827, -0.09894831],\n","       [-0.94666233, -0.03931871],\n","       [ 0.55310519,  0.12971544],\n","       [-0.7948807 , -0.19022766],\n","       [-0.74957523, -0.03623471],\n","       [ 0.48321034,  0.14154547],\n","       [-0.83346558,  0.02242846],\n","       [ 0.63394274, -0.29342916],\n","       [ 0.21679492,  0.03672528],\n","       [ 0.13584359,  0.13589867],\n","       [ 0.00414927,  0.22293107],\n","       [ 0.5653115 , -0.17521675],\n","       [ 0.52140671, -0.03953065],\n","       [ 0.37981587,  0.16197222],\n","       [ 0.32879742,  0.07453359],\n","       [-0.76153398,  0.15836202],\n","       [ 0.11129187,  0.21846251],\n","       [ 0.60073584, -0.11551626],\n","       [ 0.59459157, -0.11414648],\n","       [-0.81689704,  0.00591756],\n","       [ 0.16947171,  0.18101372],\n","       [ 0.20894645, -0.05795152],\n","       [ 0.42688391, -0.18516216],\n","       [ 0.24658371,  0.31174036],\n","       [-0.89522485,  0.08539357],\n","       [-0.75528782, -0.16314833],\n","       [-0.82759164,  0.10032488],\n","       [ 0.54042165, -0.07002172],\n","       [ 0.11898577,  0.14887481],\n","       [ 0.49442751, -0.11413974],\n","       [-0.80082432, -0.06602023]])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Simple check\n","normal = Normalizer()\n","scaled = MinMaxScaler(feature_range=(0, 1))\n","\n","normalized_X_train =normal.fit_transform(X_train)\n","scaled_X_train = scaled.fit_transform(normalized_X_train)\n","\n","print(scaled_X_train[:4])\n","\n","pcaed = PCA(n_components=2)\n","pca_X_train = pcaed.fit_transform(scaled_X_train)\n"]},{"cell_type":"markdown","metadata":{"id":"DTTN4IG1obly"},"source":["## ColumnTransformer: Managing different kinds of transformers on different columns:\n","Extracted and extended from a kaggle.com tutorial"]},{"cell_type":"markdown","metadata":{"id":"JFh1gyaPobly"},"source":["Applies transformers to columns of an array or pandas DataFrame.\n","\n","This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"VMlvwlU_oblz"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'melb_data.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmelb_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m dataset\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n","File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'melb_data.csv'"]}],"source":["dataset = pd.read_csv(\"melb_data.csv\")\n","dataset.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6kQYfCWe1M53"},"outputs":[],"source":["dataset.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAiVOuGO0dDF"},"outputs":[],"source":["dataset.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LZaxsDm7CeAH"},"outputs":[],"source":["dataset.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNV8PaHeqCy8"},"outputs":[],"source":["dataset['Price']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8Ci5WYa1aO5"},"outputs":[],"source":["#dataset = dataset[dataset['Price'].isnull()==False]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LG8rSz816JO"},"outputs":[],"source":["columns = dataset.columns.to_list()\n","columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V17ehSlf2BPl"},"outputs":[],"source":["if 'Price' in columns:\n","  columns.remove('Price')\n","\n","X = dataset[columns]\n","y = dataset['Price']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGUx1xBqyq8c"},"outputs":[],"source":["X.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DS90cjBzy0lu"},"outputs":[],"source":["#X = X[['Longtitude', 'Lattitude', 'YearBuilt', 'Car', 'Bathroom', 'Bedroom2', 'Rooms', 'Postcode']]\n","#X.isnull().any(axis=0)\n","#X.fillna(0, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m7mrMSObobl2"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2,\n","                                                      random_state=0)"]},{"cell_type":"markdown","metadata":{"id":"hGEJK9Zxobl5"},"source":["We construct the full pipeline in three steps.\n","* Step 1: Define Preprocessing Steps\n","* Step 2: Define the Model\n","* Step 3: Create and Evaluate the Pipeline"]},{"cell_type":"markdown","metadata":{"id":"0-PoHVD6obl5"},"source":["### Step 1: Define Preprocessing Steps\n","\n","Similar to how a pipeline bundles together preprocessing and modeling steps, we use the ColumnTransformer class to bundle together different preprocessing steps. The code below:\n","- imputes missing values in numerical data, and\n","- imputes missing values and applies a one-hot encoding to categorical data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jKK73oqqobl6"},"outputs":[],"source":["# \"Cardinality\" means the number of unique values in a column\n","# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n","categorical_cols = [cname for cname in X_train.columns if\n","                    X_train[cname].nunique() < 10 and\n","                    X_train[cname].dtype == \"object\"]\n","\n","# Select numerical columns\n","numerical_cols = [cname for cname in X_train.columns if\n","                X_train[cname].dtype in ['int64', 'float64']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bRUEiXIzobl9"},"outputs":[],"source":["categorical_cols"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5aNfQzDiZbEn"},"outputs":[],"source":["numerical_cols"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"92FxI0M5obmA"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Preprocessing for numerical data\n","numerical_transformer = SimpleImputer(strategy='most_frequent')\n","\n","# Preprocessing for categorical data\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse = False))\n","])\n","\n","# Bundle preprocessing for numerical and categorical data\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","       ('num', numerical_transformer, numerical_cols),\n","       ('cat', categorical_transformer, categorical_cols)\n","    ])"]},{"cell_type":"markdown","metadata":{"id":"_hRjslTmobmD"},"source":["### Step 2: Define the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eWIX8r6CobmD"},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","model = RandomForestRegressor(n_estimators=10, random_state=0)"]},{"cell_type":"markdown","metadata":{"id":"g6ai-ydFobmG"},"source":["### Step 3: Create and Evaluate the Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXNt7vkFobmG"},"outputs":[],"source":["from sklearn.metrics import mean_absolute_error\n","\n","# Bundle preprocessing and modeling code in a pipeline\n","my_pipeline = Pipeline(steps=[\n","                              ('preprocessor', preprocessor),\n","                              ('model', model),\n","                             ])\n","\n","# Preprocessing of training data, fit model\n","my_pipeline.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = my_pipeline.predict(X_test)\n","\n","# Evaluate the model\n","score = mean_absolute_error(y_test, preds)\n","print('MAE:', score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mf63rSRgEiur"},"outputs":[],"source":["sum(preds==np.NAN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S2hahHJM2WNb"},"outputs":[],"source":["sum(y_test==np.NAN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HM5NHhwxxS4Y"},"outputs":[],"source":["from sklearn.metrics import r2_score\n","\n","r2_score(y_test, preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eRfHs-yiavrp"},"outputs":[],"source":["pd.DataFrame({'label':y_test, 'preds':preds}).head(4)"]},{"cell_type":"markdown","metadata":{"id":"8K-EWe2FobmJ"},"source":["### Parameter tuning\n","\n","Setting parameters of the various steps is enabled by using their names and the parameter name separated by a ‘__’"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oq0u5V5pobmJ"},"outputs":[],"source":["# Example using a Grid Search\n","from sklearn.model_selection import GridSearchCV\n","\n","parameters = {\n","    'model__n_estimators': [1,5,10],\n","    'preprocessor__num__strategy': ['most_frequent','constant'],\n","    'preprocessor__cat__imputer__strategy': ['most_frequent','constant'],\n","}\n","\n","gs_clf = GridSearchCV(my_pipeline, parameters, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n","\n","gs_clf.fit(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvRWEnAPobmM"},"outputs":[],"source":["gs_clf.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jxrfu7-VobmP"},"outputs":[],"source":["gs_clf.best_score_"]},{"cell_type":"markdown","metadata":{"id":"KaTj0X-v35bO"},"source":["Applying the pipeline to some attributes only"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFhPlFaf35XI"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Preprocessing for numerical data\n","numerical_transformer = SimpleImputer(strategy='most_frequent')\n","\n","# Bundle preprocessing for numerical and categorical data\n","preprocessor = ColumnTransformer(\n","        transformers=[('num', numerical_transformer, numerical_cols)],\n","        remainder='passthrough')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7jI-d_zS6pE4"},"outputs":[],"source":["numerical_cols"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ct-_7Rjk35TJ"},"outputs":[],"source":["#This generates an error!\n","\n","from sklearn.metrics import mean_absolute_error\n","\n","# Bundle preprocessing and modeling code in a pipeline\n","my_pipeline = Pipeline(steps=[\n","                              ('preprocessor', preprocessor),\n","                              ('model', model),\n","                             ])\n","\n","# Preprocessing of training data, fit model\n","my_pipeline.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = my_pipeline.predict(X_test)\n","\n","# Evaluate the model\n","score = mean_absolute_error(y_test, preds)\n","print('MAE:', score)"]},{"cell_type":"markdown","metadata":{"id":"jb6_UAG65-Jm"},"source":["Remainder with estimator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5lQIptjd35Pp"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Preprocessing for numerical data\n","numerical_transformer = SimpleImputer(strategy='most_frequent')\n","\n","\n","# Bundle preprocessing for numerical and categorical data\n","preprocessor = ColumnTransformer(\n","        transformers=[('num', numerical_transformer, numerical_cols)],\n","        remainder=OneHotEncoder(handle_unknown='ignore', sparse = False))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rI97aol635LT"},"outputs":[],"source":["from sklearn.metrics import mean_absolute_error\n","\n","# Bundle preprocessing and modeling code in a pipeline\n","my_pipeline = Pipeline(steps=[\n","                              ('preprocessor', preprocessor),\n","                              ('model', model),\n","                             ])\n","\n","# Preprocessing of training data, fit model\n","my_pipeline.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = my_pipeline.predict(X_test)\n","\n","# Evaluate the model\n","score = mean_absolute_error(y_test, preds)\n","print('MAE:', score)"]},{"cell_type":"markdown","metadata":{"id":"HmDqfp6m7t0F"},"source":["Alternative techniques to indicate columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ldsWxF5eF8Ew"},"outputs":[],"source":["numerical_cols"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"raC6aGYM35Et"},"outputs":[],"source":["X_train.columns.get_indexer(numerical_cols)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kME5cfj87lbj"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Preprocessing for numerical data\n","numerical_transformer = SimpleImputer(strategy='most_frequent')\n","\n","\n","# Bundle preprocessing for numerical and categorical data\n","preprocessor = ColumnTransformer(\n","    transformers=[('num', numerical_transformer, X_train.columns.get_indexer(numerical_cols))])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yHcDPzXv72a8"},"outputs":[],"source":["preprocessor.fit_transform(X_train)"]},{"cell_type":"markdown","metadata":{"id":"lx9ZXiWu-78z"},"source":["Be carefull!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pw18OCTR_Lrd"},"outputs":[],"source":["numerical_cols"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w912RS-B72X-"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","\n","\n","# Preprocessing for all dataset\n","simple=SimpleImputer(strategy='most_frequent')\n","\n","# Preprocessing for numerical data\n","numerical_transformer = Normalizer()\n","\n","\n","# Bundle preprocessing for numerical\n","preprocessor = ColumnTransformer(\n","    transformers=[('num', numerical_transformer, numerical_cols)])\n","\n","# Bundle preprocessing\n","preprocessing_transformer = Pipeline(steps=[('simple', simple),\n","                                            ('preprocessor', preprocessor)\n","                                            ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYkUII8e-vEH"},"outputs":[],"source":["preprocessing_transformer.fit_transform(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbOWVJ98-vLF"},"outputs":[],"source":["X_train.columns.get_indexer(numerical_cols)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2irXoI--vUP"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","\n","\n","# Preprocessing for all dataset\n","simple=SimpleImputer(strategy='most_frequent')\n","\n","# Preprocessing for numerical data\n","numerical_transformer = Normalizer()\n","\n","\n","# Bundle preprocessing for numerical\n","preprocessor = ColumnTransformer(\n","    transformers=[('num', numerical_transformer, X_train.columns.get_indexer(numerical_cols))])\n","\n","# Bundle preprocessing\n","preprocessing_transformer = Pipeline(steps=[('simple', simple),\n","                                            ('preprocessor', preprocessor)\n","                                            ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-z2lo21y-vbV"},"outputs":[],"source":["preprocessing_transformer.fit_transform(X_train)"]},{"cell_type":"markdown","metadata":{"id":"jh8L2_reobmS"},"source":["## FeatureUnion: Applying multiple transformers in parallel\n","\n","Concatenates results of multiple transformer objects.\n","\n","This estimator applies a list of transformer objects in parallel to the input data, then concatenates the results. This is useful to combine several feature extraction mechanisms into a single transformer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jirOU1nHobmT"},"outputs":[],"source":["from sklearn.pipeline import FeatureUnion\n","from sklearn.decomposition import PCA, TruncatedSVD\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7jHSp7OobmW"},"outputs":[],"source":["from sklearn import datasets\n","iris = datasets.load_iris()\n","\n","X = iris.data\n","y = iris.target\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n","                                                      random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNU4BzI_B0bx"},"outputs":[],"source":["X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PXyL4nu5flE1"},"outputs":[],"source":["iris.feature_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQbn7EqTobmY"},"outputs":[],"source":["# This dataset is way too high-dimensional. Better do PCA:\n","pca = PCA(n_components=2)\n","\n","# Maybe some original features where good, too?\n","selection = SelectKBest(k=2)\n","\n","#Normalizing is always a good choice\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","\n","# Build estimator from PCA and Univariate selection:\n","combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection), (\"normal\", scaler)])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ce6C9Q3EgIa4"},"outputs":[],"source":["X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7osE0a4it7bJ"},"outputs":[],"source":["pca.fit_transform(X).shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pDVRsyN1f88J"},"outputs":[],"source":["selection.fit_transform(X, y).shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-pyfNLFXgB_N"},"outputs":[],"source":["scaler.fit_transform(X).shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_W8ifzSobma"},"outputs":[],"source":["# Use combined features to transform dataset:\n","X_features = combined_features.fit(X, y).transform(X)\n","print(\"Combined space has\", X_features.shape[1], \"features\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9gwwLKJjobmd"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","model = LogisticRegression()\n","\n","\n","# Bundle preprocessing and modeling code in a pipeline\n","my_pipeline = Pipeline(steps=[('combined_features', combined_features),\n","                              ('model', model)\n","                             ], verbose = True)\n","\n","# Preprocessing of training data, fit model\n","my_pipeline.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = my_pipeline.predict(X_valid)\n","\n","# Evaluate the model\n","score = accuracy_score(y_valid, preds)\n","print('Accuracy Score:', score)"]},{"cell_type":"markdown","metadata":{"id":"vn9o0tbbobmg"},"source":["## FunctionTransformer: Constructs a transformer from an arbitrary callable.\n","\n","Concatenates results of multiple transformer objects.\n","\n","A FunctionTransformer forwards its X (and optionally y) arguments to a user-defined function or function object and returns the result of this function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YotoIWBqobmg"},"outputs":[],"source":["from sklearn.preprocessing import FunctionTransformer\n","from sklearn.ensemble import RandomForestRegressor\n","\n","dataset = pd.read_csv(\"melb_data.csv\")\n","columns = dataset.columns.to_list()\n","columns.remove('Price')\n","\n","X = dataset[columns]\n","y = dataset['Price']\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n","                                                      random_state=0)\n","\n","#Selecting the numerical columns\n","def columns_num(X):\n","    numerical_cols = [cname for cname in X.columns if  X[cname].dtype in ['int64', 'float64']]\n","    return X.loc[:,numerical_cols]\n","\n","fill_na_transformer = Pipeline(steps=[ ('drop_cols', FunctionTransformer(columns_num, validate=False)),\n","                                       ('fill_na', SimpleImputer(strategy='most_frequent'))  ], verbose=True)\n","\n","\n","model = RandomForestRegressor(n_estimators=100, random_state=0)\n","\n","\n","\n","# Bundle preprocessing and modeling code in a pipeline\n","my_pipeline = Pipeline(steps=[('preprocessor', fill_na_transformer),\n","                              ('model', model)\n","                             ])\n","\n","# Preprocessing of training data, fit model\n","my_pipeline.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = my_pipeline.predict(X_valid)\n","\n","# Evaluate the model\n","#score = mean_absolute_error(y_valid, preds)\n","#print('MAE:', score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3G-fIF9meCux"},"outputs":[],"source":["fill_na_transformer.fit_transform(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eStlaWKVR519"},"outputs":[],"source":["fill_na_transformer = Pipeline(steps=[ ('drop_cols', FunctionTransformer(columns_num, validate=True)),\n","                                       ('fill_na', SimpleImputer(strategy='most_frequent'))  ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aCZBPavrR9-7"},"outputs":[],"source":["fill_na_transformer.fit_transform(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gv-nhf4RR_dx"},"outputs":[],"source":["columns_num(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hezaP5MOTY61"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
